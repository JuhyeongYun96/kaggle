{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, psutil  \n",
    "\n",
    "def cpu_stats():\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    memory_use = py.memory_info()[0] / 2. ** 30\n",
    "    return 'memory GB:' + str(np.round(memory_use, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/bengaliai-cv19/test_image_data_2.parquet\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_3.parquet\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_0.parquet\n",
      "/kaggle/input/bengaliai-cv19/train.csv\n",
      "/kaggle/input/bengaliai-cv19/class_map_corrected.csv\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_1.parquet\n",
      "/kaggle/input/bengaliai-cv19/train_multi_diacritics.csv\n",
      "/kaggle/input/bengaliai-cv19/class_map.csv\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_3.parquet\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_2.parquet\n",
      "/kaggle/input/bengaliai-cv19/test.csv\n",
      "/kaggle/input/bengaliai-cv19/sample_submission.csv\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_1.parquet\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_0.parquet\n",
      "/kaggle/input/kerasefficientnetb3/Train1_model_70.h5\n",
      "/kaggle/input/kerasefficientnetb3/efficientnet-1.0.0-py3-none-any.whl\n",
      "/kaggle/input/kerasefficientnetb3/Train1_model_64.h5\n",
      "/kaggle/input/kerasefficientnetb3/Train1_model_57.h5\n",
      "/kaggle/input/kerasefficientnetb3/Train1_model_68.h5\n",
      "/kaggle/input/kerasefficientnetb3/Train1_model_66.h5\n",
      "/kaggle/input/kerasefficientnetb3/Train1_model_59.h5\n",
      "/kaggle/input/ghostnetbengali/densenet121-checkpoint.pt\n",
      "/kaggle/input/ghostnetbengali/checkpoint-18.pt\n",
      "/kaggle/input/ghostnetbengali/checkpoint.pt\n",
      "/kaggle/input/ghostnetbengali/checkpoint-15.pt\n",
      "/kaggle/input/ghostnetbengali/checkpoint-17.pt\n",
      "/kaggle/input/ghostnetbengali/checkpoint-16.pt\n",
      "/kaggle/input/ghostnetbengali/ghost_net.py\n",
      "/kaggle/input/ghostnetbengali/readme.md\n",
      "/kaggle/input/ghostnetbengali/fig/flops_latency.png\n",
      "/kaggle/input/ghostnetbengali/fig/ghost_module.png\n",
      "/kaggle/input/efficientnet-resnet-ensemble/submission_resnext.csv\n",
      "/kaggle/input/efficientnet-resnet-ensemble/resnet_func.py\n",
      "/kaggle/input/efficientnet-resnet-ensemble/custom.css\n",
      "/kaggle/input/efficientnet-resnet-ensemble/__notebook__.ipynb\n",
      "/kaggle/input/efficientnet-resnet-ensemble/resnetbase.py\n",
      "/kaggle/input/efficientnet-resnet-ensemble/__results__.html\n",
      "/kaggle/input/efficientnet-resnet-ensemble/__output__.json\n",
      "/kaggle/input/efficientnet-resnet-ensemble/resnet_setup.py\n",
      "/kaggle/input/efficientnet-resnet-ensemble/submission.csv\n",
      "/kaggle/input/efficientnet-resnet-ensemble/predict_on_video_resnet.py\n",
      "/kaggle/input/efficientnet-resnet-ensemble/predict_on_set.py\n",
      "/kaggle/input/efficientnet-resnet-ensemble/__pycache__/resnet_func.cpython-36.pyc\n",
      "/kaggle/input/efficientnet-resnet-ensemble/__pycache__/resnet_setup.cpython-36.pyc\n",
      "/kaggle/input/efficientnet-resnet-ensemble/__pycache__/predict_on_video_resnet.cpython-36.pyc\n",
      "/kaggle/input/se-resnext50-32x4d-fold2/se_resnext50_32x4d_fold2.pkl\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import time, gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로\n",
    "DIR = '../input/bengaliai-cv19'\n",
    "test_loc = 'test_image_data_'\n",
    "#test_loc = 'train_image_data_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "#sys.path.insert(0, \"/kaggle/input/ghostnet\")\n",
    "sys.path.insert(0, \"/kaggle/input/ghostnetbengali\")\n",
    "\n",
    "from ghost_net import ghost_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory GB:0.21'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 137, 236\n",
    "\n",
    "\n",
    "class DatasetRetriever(Dataset):\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.image_ids = df.iloc[:, 0].tolist()\n",
    "        self.images = torch.from_numpy(255 - df[[str(x) for x in range(32332)]].values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        img = img.view(*IMAGE_SIZE)\n",
    "        img = img.to(torch.float32) / 255.\n",
    "        img = img.unsqueeze(0)\n",
    "        img = img.repeat(3, 1, 1)\n",
    "        img_id = self.image_ids[idx]        \n",
    "        return img_id, img\n",
    "    \n",
    "class Predictor:\n",
    "    def __init__(self, model):\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model.to(self.device, dtype=torch.float32);\n",
    "        self.model.eval()\n",
    "        print(f'Model prepared. Device is {self.device}')\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        inputs = inputs.to(self.device, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(inputs)\n",
    "        return outputs\n",
    "\n",
    "    def load(self, path):\n",
    "        checkpoint = torch.load(path, map_location=self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory GB:0.21'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prepared. Device is cuda:0\n",
      "Model prepared. Device is cuda:0\n"
     ]
    }
   ],
   "source": [
    "predictors = []\n",
    "\n",
    "for i, model_path in enumerate([\n",
    "    #'/kaggle/input/ghostnetbengali/checkpoint.pt',\n",
    "    #'/kaggle/input/ghostnetbengali/checkpoint-15.pt',\n",
    "    #'/kaggle/input/ghostnetbengali/checkpoint-16.pt',\n",
    "    '/kaggle/input/ghostnetbengali/checkpoint-17.pt',\n",
    "    '/kaggle/input/ghostnetbengali/checkpoint-18.pt',\n",
    "]):\n",
    "    predictor = Predictor(ghost_net(num_classes=168+11+7))\n",
    "    predictor.load(model_path)\n",
    "    predictors.append(predictor)\n",
    "\n",
    "predictors_count = len(predictors)\n",
    "\n",
    "\n",
    "def predict_to_numpy(predict):\n",
    "    return torch.nn.functional.softmax(predict, dim=1).data.cpu().numpy()\n",
    "\n",
    "def make_prediction(images):\n",
    "    outputs = 0\n",
    "    for predictor in predictors:\n",
    "        outputs += predictor.predict(images) / predictors_count\n",
    "\n",
    "    roots = predict_to_numpy(outputs[:,:168])\n",
    "    vowels = predict_to_numpy(outputs[:,168:168+11])\n",
    "    consonants = predict_to_numpy(outputs[:,168+11:])\n",
    "    return roots, vowels, consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory GB:1.83'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "CPU times: user 11.7 s, sys: 2.41 s, total: 14.1 s\n",
      "Wall time: 12.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nxx=[0,3,6,9,12,15,18,21,24,27,30,33]\\nyy=[1,4,7,10,13,16,19,22,25,28,31,34]\\nzz=[2,5,8,11,14,17,20,23,26,29,32,35]\\n\\nfor i in xx:\\n    roots_prob_ghost.append(targets[i])\\n    \\nfor i in yy:\\n    vowels_prob_ghost.append(targets[i])\\n    \\nfor i in zz:\\n    consonants_prob_ghost.append(targets[i])\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "target = []\n",
    "row_id = []\n",
    "\n",
    "roots_id_ghost=[]\n",
    "roots_prob_ghost=[]\n",
    "\n",
    "vowels_id_ghost=[]\n",
    "vowels_prob_ghost=[]\n",
    "\n",
    "consonants_id_ghost=[]\n",
    "consonants_prob_ghost=[]\n",
    "\n",
    "for i in range(4):\n",
    "    data = pd.read_parquet(os.path.join(DIR, test_loc+str(i)+'.parquet'))\n",
    "    #data = pd.read_parquet(f'../input/bengaliai-cv19/test_image_data_{i}.parquet')\n",
    "    dataset = DatasetRetriever(data)\n",
    "    data_loader = DataLoader(dataset, batch_size=256, num_workers=4, shuffle=False, sampler=SequentialSampler(dataset))\n",
    "\n",
    "    for idx, (image_ids, images) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "\n",
    "        roots, vowels, consonants = make_prediction(images)\n",
    "\n",
    "        #for image_id, root, vowel, consonant in zip(image_ids, roots, vowels, consonants):\n",
    "        for root, vowel, consonant in zip(roots, vowels, consonants):\n",
    "            #원본\n",
    "            #row_id.append(image_id + '_consonant_diacritic')\n",
    "            #target.append(consonant)\n",
    "            #row_id.append(image_id + '_grapheme_root')\n",
    "            #target.append(root)\n",
    "            #row_id.append(image_id + '_vowel_diacritic')\n",
    "            #target.append(vowel)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #roots_prob_ghost.append(roots)\n",
    "            #vowels_prob_ghost.append(vowels)\n",
    "            #consonants_prob_ghost.append(consonants)             \n",
    "            \n",
    "            \n",
    "            roots_prob_ghost.append(root)\n",
    "            vowels_prob_ghost.append(vowel)\n",
    "            consonants_prob_ghost.append(consonant)    \n",
    "            \n",
    "    del data\n",
    "    del dataset\n",
    "    del data_loader\n",
    "    collected = gc.collect()\n",
    "    print(collected)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "'''\n",
    "xx=[0,3,6,9,12,15,18,21,24,27,30,33]\n",
    "yy=[1,4,7,10,13,16,19,22,25,28,31,34]\n",
    "zz=[2,5,8,11,14,17,20,23,26,29,32,35]\n",
    "\n",
    "for i in xx:\n",
    "    roots_prob_ghost.append(targets[i])\n",
    "    \n",
    "for i in yy:\n",
    "    vowels_prob_ghost.append(targets[i])\n",
    "    \n",
    "for i in zz:\n",
    "    consonants_prob_ghost.append(targets[i])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory GB:2.22'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(roots_prob_ghost[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 168)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(roots_prob_ghost).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([9.9987340e-01, 1.2656204e-04, 1.1907238e-12, 1.4297954e-12,\n",
       "        1.2924976e-10, 2.8937708e-11, 9.7344096e-14, 6.5999772e-13,\n",
       "        1.2500098e-15, 3.4346459e-09, 1.1532775e-15], dtype=float32),\n",
       " array([1.1956422e-05, 7.9956525e-10, 9.9998653e-01, 1.4017409e-06,\n",
       "        1.4398896e-08, 4.1639157e-12, 4.3190666e-11, 2.8399613e-08,\n",
       "        1.9454152e-08, 4.0909694e-13, 9.2727926e-12], dtype=float32),\n",
       " array([9.9998653e-01, 6.4678659e-07, 2.9132932e-06, 4.0218990e-07,\n",
       "        4.0837799e-06, 2.4406546e-09, 8.4422830e-08, 5.1561433e-06,\n",
       "        5.5941055e-12, 1.0488938e-13, 2.4883201e-07], dtype=float32),\n",
       " array([9.9990249e-01, 9.3521325e-05, 9.3598260e-08, 6.6723560e-09,\n",
       "        1.0657799e-08, 2.3611472e-06, 1.1703808e-06, 2.4364988e-07,\n",
       "        1.0564784e-07, 8.4521253e-12, 8.8053593e-13], dtype=float32),\n",
       " array([5.0322815e-05, 7.6318179e-12, 4.7780702e-10, 1.5754531e-11,\n",
       "        9.9994540e-01, 8.5513375e-07, 3.3595029e-07, 3.0938641e-06,\n",
       "        4.0547037e-09, 1.9497434e-13, 5.2426986e-11], dtype=float32),\n",
       " array([3.3376184e-06, 3.7098282e-08, 9.9995255e-01, 2.5398526e-06,\n",
       "        9.9379982e-08, 2.3367688e-10, 8.8790936e-10, 1.4173620e-05,\n",
       "        2.3416245e-05, 4.1207892e-07, 3.4459408e-06], dtype=float32),\n",
       " array([1.8195279e-09, 1.0233114e-04, 9.1095981e-14, 1.8717887e-11,\n",
       "        1.3546259e-13, 4.0330937e-11, 1.7800304e-14, 3.9482520e-06,\n",
       "        1.1515540e-10, 9.9989355e-01, 1.0724532e-07], dtype=float32),\n",
       " array([2.5829445e-07, 1.6225792e-12, 2.1548979e-07, 5.9777973e-12,\n",
       "        8.7812552e-12, 1.2509759e-18, 4.8638739e-16, 9.9999905e-01,\n",
       "        7.6244406e-09, 5.2801823e-07, 4.8387205e-10], dtype=float32),\n",
       " array([1.3496794e-09, 3.4381344e-06, 2.8440461e-10, 1.4240425e-13,\n",
       "        9.1939579e-14, 7.2475366e-11, 1.2286347e-16, 1.3598241e-05,\n",
       "        5.2333263e-14, 9.9998295e-01, 1.2861735e-10], dtype=float32),\n",
       " array([1.0113919e-18, 1.0945197e-16, 7.6604542e-15, 2.2283883e-11,\n",
       "        5.5277648e-25, 9.0791863e-24, 8.6504133e-23, 1.7710571e-11,\n",
       "        1.2282766e-14, 6.3935221e-07, 9.9999940e-01], dtype=float32),\n",
       " array([3.2371463e-04, 9.9967599e-01, 8.1436756e-13, 5.9477654e-09,\n",
       "        3.0893113e-07, 1.0515880e-10, 6.6405295e-09, 9.5399091e-11,\n",
       "        1.0066186e-13, 5.3822749e-08, 5.8947348e-15], dtype=float32),\n",
       " array([8.7171909e-10, 1.8429918e-09, 9.9999988e-01, 9.5559533e-14,\n",
       "        2.8245621e-14, 1.9643158e-15, 2.9017990e-14, 1.2724279e-07,\n",
       "        5.6463344e-11, 2.7871860e-10, 1.2130237e-13], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowels_prob_ghost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 168)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(roots_prob_ghost).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vowels_prob_ghost).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(roots_prob_ghost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory GB:2.22'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom tqdm import tqdm\\n\\nroots_id_ghost=[]\\nroots_prob_ghost=[]\\n\\nvowels_id_ghost=[]\\nvowels_prob_ghost=[]\\n\\nconsonants_id_ghost=[]\\nconsonants_prob_ghost=[]\\n\\nfor i in tqdm(range(0, 4)):\\n    #data = pd.read_parquet(f'../input/bengaliai-cv19/test_image_data_{i}.parquet')\\n    data = pd.read_parquet(os.path.join(DIR, test_loc+str(i)+'.parquet'))\\n    dataset = DatasetRetriever(data)\\n    del data\\n    data_loader = DataLoader(dataset, batch_size=64, num_workers=0, shuffle=False, sampler=SequentialSampler(dataset))\\n    \\n    id_t=[]\\n    data_t=[]\\n    \\n    \\n    #del data\\n    \\n    for x_id,x_data in data_loader:\\n        id_t.append(x_id)\\n        data_t.append(x_data)\\n        \\n        roots, vowels, consonants = make_prediction(x_data)\\n        \\n        roots_prob_ghost.append(roots)\\n        vowels_prob_ghost.append(vowels)\\n        consonants_prob_ghost.append(consonants)    \\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from tqdm import tqdm\n",
    "\n",
    "roots_id_ghost=[]\n",
    "roots_prob_ghost=[]\n",
    "\n",
    "vowels_id_ghost=[]\n",
    "vowels_prob_ghost=[]\n",
    "\n",
    "consonants_id_ghost=[]\n",
    "consonants_prob_ghost=[]\n",
    "\n",
    "for i in tqdm(range(0, 4)):\n",
    "    #data = pd.read_parquet(f'../input/bengaliai-cv19/test_image_data_{i}.parquet')\n",
    "    data = pd.read_parquet(os.path.join(DIR, test_loc+str(i)+'.parquet'))\n",
    "    dataset = DatasetRetriever(data)\n",
    "    del data\n",
    "    data_loader = DataLoader(dataset, batch_size=64, num_workers=0, shuffle=False, sampler=SequentialSampler(dataset))\n",
    "    \n",
    "    id_t=[]\n",
    "    data_t=[]\n",
    "    \n",
    "    \n",
    "    #del data\n",
    "    \n",
    "    for x_id,x_data in data_loader:\n",
    "        id_t.append(x_id)\n",
    "        data_t.append(x_data)\n",
    "        \n",
    "        roots, vowels, consonants = make_prediction(x_data)\n",
    "        \n",
    "        roots_prob_ghost.append(roots)\n",
    "        vowels_prob_ghost.append(vowels)\n",
    "        consonants_prob_ghost.append(consonants)    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# efficient net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/kerasefficientnetb3/efficientnet-1.0.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.6/site-packages (from efficientnet==1.0.0) (1.0.8)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.6/site-packages (from efficientnet==1.0.0) (0.16.2)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0) (2.10.0)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0) (1.18.1)\r\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (1.1.1)\r\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (2.6.1)\r\n",
      "Requirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (1.4.1)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (3.0.3)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (2.4)\r\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (5.4.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0) (1.14.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (1.1.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (2.4.6)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (2.8.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0) (4.4.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (45.2.0.post20200210)\r\n",
      "Installing collected packages: efficientnet\r\n",
      "Successfully installed efficientnet-1.0.0\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import time, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dense, Lambda\n",
    "from math import ceil\n",
    "\n",
    "# Install EfficientNet\n",
    "!pip install '../input/kerasefficientnetb3/efficientnet-1.0.0-py3-none-any.whl'\n",
    "import efficientnet.keras as efn\n",
    "#!pip install keras_efficientnets\n",
    "#from keras_efficientnets import EfficientNetB3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 설정\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "FACTOR = 0.70\n",
    "HEIGHT_NEW = int(HEIGHT * FACTOR)\n",
    "WIDTH_NEW = int(WIDTH * FACTOR)\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 16 #16\n",
    "\n",
    "# 경로\n",
    "#DIR = '../input/bengaliai-cv19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Image Prep\n",
    "def resize_image(img, WIDTH_NEW, HEIGHT_NEW):\n",
    "    # Invert\n",
    "    img = 255 - img\n",
    "\n",
    "    # Normalize\n",
    "    img = (img * (255.0 / img.max())).astype(np.uint8)\n",
    "\n",
    "    # Reshape\n",
    "    img = img.reshape(HEIGHT, WIDTH)\n",
    "    image_resized = cv2.resize(img, (WIDTH_NEW, HEIGHT_NEW), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    return image_resized.reshape(-1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalized mean pool - GeM\n",
    "gm_exp = tf.Variable(3.0, dtype = tf.float32)\n",
    "def generalized_mean_pool_2d(X):\n",
    "    pool = (tf.reduce_mean(tf.abs(X**(gm_exp)), \n",
    "                        axis = [1, 2], \n",
    "                        keepdims = False) + 1.e-7)**(1./gm_exp)\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "\n",
    "def create_model(input_shape):\n",
    "    # Input Layer\n",
    "    input = Input(shape = input_shape)\n",
    "    \n",
    "    # Create and Compile Model and show Summary\n",
    "    x_model = efn.EfficientNetB3(weights = None, include_top = False, input_tensor = input, pooling = None, classes = None)\n",
    "    \n",
    "    # UnFreeze all layers\n",
    "    for layer in x_model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # GeM\n",
    "    lambda_layer = Lambda(generalized_mean_pool_2d)\n",
    "    lambda_layer.trainable_weights.extend([gm_exp])\n",
    "    x = lambda_layer(x_model.output)\n",
    "    \n",
    "    # multi output\n",
    "    grapheme_root = Dense(168, activation = 'softmax', name = 'root')(x)\n",
    "    vowel_diacritic = Dense(11, activation = 'softmax', name = 'vowel')(x)\n",
    "    consonant_diacritic = Dense(7, activation = 'softmax', name = 'consonant')(x)\n",
    "\n",
    "    # model\n",
    "    model = Model(inputs = x_model.input, outputs = [grapheme_root, vowel_diacritic, consonant_diacritic])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory GB:2.84'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, X, batch_size = 16, img_size = (128, 128, 3), *args, **kwargs):\n",
    "        self.X = X\n",
    "        self.indices = np.arange(len(self.X))\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return int(ceil(len(self.X) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        X = self.__data_generation(indices)\n",
    "        return X\n",
    "    \n",
    "    def __data_generation(self, indices):\n",
    "        X = np.empty((self.batch_size, *self.img_size))\n",
    "        \n",
    "        for i, index in enumerate(indices):\n",
    "            image = self.X[index]\n",
    "            image = np.stack((image,)*CHANNELS, axis=-1)\n",
    "            image = image.reshape(-1, HEIGHT_NEW, WIDTH_NEW, CHANNELS)\n",
    "            \n",
    "            X[i,] = image\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory GB:2.84'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = create_model(input_shape = (HEIGHT_NEW, WIDTH_NEW, CHANNELS))\n",
    "model5.load_weights('../input/kerasefficientnetb3/Train1_model_70.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory GB:2.97'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del dataloaders\n",
    "#del data_generator_test \n",
    "#gc.collect() 순서대로 run했으면 필요없는 셀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory GB:2.97'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:09<00:28,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:12<00:15,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:15<00:06,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:18<00:00,  4.56s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from se_resnext import make_loader\n",
    "\n",
    "# 컬럼명\n",
    "tgt_cols = ['grapheme_root','vowel_diacritic','consonant_diacritic']\n",
    "\n",
    "# 예측값 담는 리스트\n",
    "row_ids, targets = [], []\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, 4)):\n",
    "    test_files = []\n",
    "    \n",
    "    # Read Parquet file\n",
    "    df = pd.read_parquet(os.path.join(DIR, test_loc+str(i)+'.parquet'))\n",
    "    # Get Image Id values\n",
    "    image_ids = df['image_id'].values \n",
    "    # Drop Image_id column\n",
    "    dataloaders = make_loader(data_folder = df,\n",
    "                                       batch_size=BATCH_SIZE,\n",
    "                                       num_workers = 2,\n",
    "                                       is_shuffle = False)\n",
    "    df = df.drop(['image_id'], axis = 1)\n",
    "    \n",
    "    \n",
    "    X = []\n",
    "    for image_id, index in zip(image_ids, range(df.shape[0])):\n",
    "        test_files.append(image_id)\n",
    "        X.append(resize_image(df.loc[df.index[index]].values, WIDTH_NEW, HEIGHT_NEW))\n",
    "\n",
    "        \n",
    "    del df\n",
    "    gc.collect()\n",
    "        \n",
    "    # Data_Generator\n",
    "    data_generator_test = TestDataGenerator(X, batch_size = BATCH_SIZE, img_size = (HEIGHT_NEW, WIDTH_NEW, CHANNELS))\n",
    "    preds5 = model5.predict_generator(data_generator_test, verbose = 1)\n",
    "\n",
    "    \n",
    "    del dataloaders\n",
    "    del data_generator_test\n",
    "    #del model5 이거 주석풀면 preds5 = 라인에서 뒤짐\n",
    "    gc.collect()\n",
    "    cpu_stats()\n",
    "    \n",
    "    for i, image_id in zip(range(len(test_files)), test_files):\n",
    "        \n",
    "        for subi, col in zip(range(len(preds5)), tgt_cols):\n",
    "            sub_preds5 = preds5[subi]\n",
    "\n",
    "            # Set Prediction with average of 5 predictions\n",
    "            row_ids.append(str(image_id)+'_'+col)\n",
    "            sub_pred_value =sub_preds5[i] \n",
    "            targets.append(sub_pred_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory GB:3.31'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#row_ids, targets = [], [] 나중에는 지워서 램 절약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nxx=[0,3,6,9,12,15,18,21,24,27,30,33]\\nyy=[1,4,7,10,13,16,19,22,25,28,31,34]\\nzz=[2,5,8,11,14,17,20,23,26,29,32,35]\\n\\nfor i in xx:\\n    roots_prob_effi.append(targets[i])\\n    \\nfor i in yy:\\n    vowels_prob_effi.append(targets[i])\\n    \\nfor i in zz:\\n    consonants_prob_effi.append(targets[i])\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roots_prob_effi=[]\n",
    "vowels_prob_effi=[]\n",
    "consonants_prob_effi=[]\n",
    "\n",
    "for i in range(0, len(targets)//3):\n",
    "    roots_prob_effi.append(targets[i*3])\n",
    "    \n",
    "for i in range(0, len(targets)//3):\n",
    "    vowels_prob_effi.append(targets[i*3+1])\n",
    "    \n",
    "for i in range(0, len(targets)//3):\n",
    "    consonants_prob_effi.append(targets[i*3+2])\n",
    "\n",
    "\n",
    "'''\n",
    "xx=[0,3,6,9,12,15,18,21,24,27,30,33]\n",
    "yy=[1,4,7,10,13,16,19,22,25,28,31,34]\n",
    "zz=[2,5,8,11,14,17,20,23,26,29,32,35]\n",
    "\n",
    "for i in xx:\n",
    "    roots_prob_effi.append(targets[i])\n",
    "    \n",
    "for i in yy:\n",
    "    vowels_prob_effi.append(targets[i])\n",
    "    \n",
    "for i in zz:\n",
    "    consonants_prob_effi.append(targets[i])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 168)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(roots_prob_effi).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory GB:3.31'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 168)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(roots_prob_effi).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(vowels_prob_effi).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# se-resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms as torchtransforms\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "from torch.utils import model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory GB:3.31'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "modelpath = \"/kaggle/input/se-resnext50-32x4d-fold2/se_resnext50_32x4d_fold2.pkl\"\n",
    "#modelpath = \"/kaggle/input/se-resnext50-32x4d-fold3/se_resnext50_32x4d_fold3.pkl\"\n",
    "root_path=\"/kaggle/input/bengaliai-cv19\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory GB:3.31'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmodeleval(model, dataloaders):\n",
    "    model.eval()\n",
    "    #tbar = tqdm(dataloaders)\n",
    "    results = []\n",
    "    pathes=[]\n",
    "\n",
    "    alllogit1 = []\n",
    "    alllogit2 = []\n",
    "    alllogit3 = []\n",
    "    for path, img in dataloaders:\n",
    "        img = img.to(device)\n",
    "        pathes.extend(path)\n",
    "        with torch.no_grad():\n",
    "            output = model(img)\n",
    "        logit1, logit2, logit3 = output[:,: 168],\\\n",
    "                                    output[:,168: 168+11],\\\n",
    "                                    output[:,168+11:]\n",
    "        logit1 = F.softmax(logit1, dim=1).cpu().numpy()  # softmax\n",
    "        logit2 = F.softmax(logit2, dim=1).cpu().numpy()\n",
    "        logit3 = F.softmax(logit3, dim=1).cpu().numpy()\n",
    "        alllogit1.extend(logit1.tolist())\n",
    "        alllogit2.extend(logit2.tolist())\n",
    "        alllogit3.extend(logit3.tolist())\n",
    "    alllogit1 = np.array(alllogit1)\n",
    "    alllogit2 = np.array(alllogit2)\n",
    "    alllogit3 = np.array(alllogit3)\n",
    "    results.append(alllogit1)\n",
    "    results.append(alllogit2)\n",
    "    results.append(alllogit3)\n",
    "    return pathes, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from se_resnext import make_loader\n",
    "from se_resnext import se_resnext50_32x4d\n",
    "model6 = se_resnext50_32x4d(pretrained=None)\n",
    "model6.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "model6.last_linear = nn.Linear(model6.last_linear.in_features, 186)\n",
    "modelvalue = torch.load(modelpath, map_location='cpu')\n",
    "#modelvalue = torch.load(modelpath, map_location='cuda:0')\n",
    "newmodelvalue = {}\n",
    "for kv in modelvalue:\n",
    "    newmodelvalue[kv[4:]]=modelvalue[kv]        \n",
    "model6.load_state_dict(newmodelvalue)\n",
    "model6 = model6.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory GB:3.36'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del dataloaders\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory GB:3.36'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory GB:3.36'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del dataloaders\n",
    "#del df 램 용량 많이 먹음\n",
    "gc.collect()\n",
    "cpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memory GB:3.36'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "cpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.96s/it]\n"
     ]
    }
   ],
   "source": [
    "roots_prob_res=[]\n",
    "vowels_prob_res=[]\n",
    "consonants_prob_res=[]\n",
    "\n",
    "# Create Submission File\n",
    "tgt_cols = ['grapheme_root','vowel_diacritic','consonant_diacritic']\n",
    "\n",
    "# Create Predictions\n",
    "row_ids, targets = [], []\n",
    "\n",
    "# Loop through Test Parquet files (X)\n",
    "for i in tqdm(range(0, 4)):\n",
    "    # Test Files Placeholder\n",
    "    test_files = []\n",
    "\n",
    "    # Read Parquet file\n",
    "    df = pd.read_parquet(os.path.join(DIR, test_loc+str(i)+'.parquet'))\n",
    "    # Get Image Id values\n",
    "    image_ids = df['image_id'].values \n",
    "    # Drop Image_id column\n",
    "    dataloaders = make_loader(data_folder = df,\n",
    "                                       batch_size=8,\n",
    "                                       num_workers = 0, # 원본 : 2\n",
    "                                       is_shuffle = False)\n",
    "    df = df.drop(['image_id'], axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 삽입한 코드  \n",
    "    \n",
    "    X = []\n",
    "    for image_id, index in zip(image_ids, range(df.shape[0])):\n",
    "        test_files.append(image_id)\n",
    "        X.append(resize_image(df.loc[df.index[index]].values, WIDTH_NEW, HEIGHT_NEW))\n",
    "    \n",
    "    # 삽입한 코드 end\n",
    "    \n",
    "    \n",
    "\n",
    "    data_generator_test = TestDataGenerator(X, batch_size = BATCH_SIZE, img_size = (HEIGHT_NEW, WIDTH_NEW, CHANNELS))\n",
    "    \n",
    "    pathes6, preds6 = getmodeleval(model6, dataloaders)\n",
    "    \n",
    "    \n",
    "    for kk in preds6[0]:\n",
    "        roots_prob_res.append(kk)\n",
    "    \n",
    "    for kk in preds6[1]:\n",
    "        vowels_prob_res.append(kk)\n",
    "    \n",
    "    for kk in preds6[2]:\n",
    "        consonants_prob_res.append(kk)\n",
    "        \n",
    "    del dataloaders\n",
    "    del df\n",
    "    gc.collect()\n",
    "    cpu_stats()\n",
    "    \n",
    "    # Cleanup\n",
    "    #del df\n",
    "    #gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nroots_prob_ghost_q=[]\\nvowels_prob_ghost_q=[]\\nconsonants_prob_ghost_q=[]\\n\\n\\nfor i in roots_prob_ghost:\\n    for j in i:\\n        roots_prob_ghost_q.append(j)\\n        \\nfor i in vowels_prob_ghost:\\n    for j in i:\\n        vowels_prob_ghost_q.append(j)\\n\\nfor i in consonants_prob_ghost:\\n    for j in i:\\n        consonants_prob_ghost_q.append(j)\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 빼내기\n",
    "#roots_prob_ghost_q 대신 roots_prob_ghost 사용하므로 필요없는 셀이다\n",
    "'''\n",
    "roots_prob_ghost_q=[]\n",
    "vowels_prob_ghost_q=[]\n",
    "consonants_prob_ghost_q=[]\n",
    "\n",
    "\n",
    "for i in roots_prob_ghost:\n",
    "    for j in i:\n",
    "        roots_prob_ghost_q.append(j)\n",
    "        \n",
    "for i in vowels_prob_ghost:\n",
    "    for j in i:\n",
    "        vowels_prob_ghost_q.append(j)\n",
    "\n",
    "for i in consonants_prob_ghost:\n",
    "    for j in i:\n",
    "        consonants_prob_ghost_q.append(j)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n데이터 셋\\n\\nroots_prob_ghost\\nvowels_prob_ghost\\nconsonants_prob_ghost\\n\\nroots_prob_ghost_q\\nvowels_prob_ghost_q\\nconsonants_prob_ghost_q\\n\\nroots_prob_effi\\nvowels_prob_effi\\nconsonants_prob_effi\\n\\nroots_prob_res\\nvowels_prob_res\\nconsonants_prob_res\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "데이터 셋\n",
    "\n",
    "roots_prob_ghost\n",
    "vowels_prob_ghost\n",
    "consonants_prob_ghost\n",
    "\n",
    "roots_prob_ghost_q\n",
    "vowels_prob_ghost_q\n",
    "consonants_prob_ghost_q\n",
    "\n",
    "roots_prob_effi\n",
    "vowels_prob_effi\n",
    "consonants_prob_effi\n",
    "\n",
    "roots_prob_res\n",
    "vowels_prob_res\n",
    "consonants_prob_res\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 168)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(roots_prob_res).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 168)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(roots_prob_effi).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 168)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(roots_prob_ghost).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# denseNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from torchvision.models.densenet import densenet121\n",
    "\n",
    "sys.path.insert(0, \"/kaggle/input/ghostnetbengali\")\n",
    "\n",
    "from ghost_net import ghost_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 137, 236\n",
    "\n",
    "\n",
    "class DatasetRetriever(Dataset):\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.image_ids = df.iloc[:, 0].tolist()\n",
    "        self.images = torch.from_numpy(255 - df[[str(x) for x in range(32332)]].values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        img = img.view(*IMAGE_SIZE)\n",
    "        img = img.to(torch.float32) / 255.\n",
    "        img = img.unsqueeze(0)\n",
    "        img = img.repeat(3, 1, 1)\n",
    "        img_id = self.image_ids[idx]        \n",
    "        return img_id, img\n",
    "    \n",
    "class Predictor:\n",
    "    def __init__(self, model):\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model.to(self.device, dtype=torch.float32);\n",
    "        self.model.eval()\n",
    "        print(f'Model prepared. Device is {self.device}')\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        inputs = inputs.to(self.device, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(inputs)\n",
    "        return outputs\n",
    "\n",
    "    def load(self, path):\n",
    "        checkpoint = torch.load(path, map_location=self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prepared. Device is cuda:0\n"
     ]
    }
   ],
   "source": [
    "predictors = []\n",
    "\n",
    "for i, model_path in enumerate([\n",
    "'/kaggle/input/ghostnetbengali/densenet121-checkpoint.pt',\n",
    "]):\n",
    "    predictor = Predictor(densenet121(num_classes=168+11+7))\n",
    "    predictor.load(model_path)\n",
    "    predictors.append(predictor)\n",
    "\n",
    "predictors_count = len(predictors)\n",
    "\n",
    "\n",
    "def predict_to_numpy(predict):\n",
    "    return torch.nn.functional.softmax(predict, dim=1).data.cpu().numpy()\n",
    "\n",
    "def make_prediction(images):\n",
    "    outputs = 0\n",
    "    for predictor in predictors:\n",
    "        outputs += predictor.predict(images) / predictors_count\n",
    "\n",
    "    roots = predict_to_numpy(outputs[:,:168])\n",
    "    vowels = predict_to_numpy(outputs[:,168:168+11])\n",
    "    consonants = predict_to_numpy(outputs[:,168+11:])\n",
    "    return roots, vowels, consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  7.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 2.31 s, total: 14.4 s\n",
      "Wall time: 12.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "target = []\n",
    "row_id = []\n",
    "\n",
    "roots_id_dense=[]\n",
    "roots_prob_dense=[]\n",
    "\n",
    "vowels_id_dense=[]\n",
    "vowels_prob_dense=[]\n",
    "\n",
    "consonants_id_dense=[]\n",
    "consonants_prob_dense=[]\n",
    "\n",
    "for i in range(4):\n",
    "    data = pd.read_parquet(os.path.join(DIR, test_loc+str(i)+'.parquet'))\n",
    "    #data = pd.read_parquet(f'../input/bengaliai-cv19/test_image_data_{i}.parquet')\n",
    "    dataset = DatasetRetriever(data)\n",
    "    data_loader = DataLoader(dataset, batch_size=256, num_workers=4, shuffle=False, sampler=SequentialSampler(dataset))\n",
    "\n",
    "    for idx, (image_ids, images) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "\n",
    "        roots, vowels, consonants = make_prediction(images)\n",
    "\n",
    "        #for image_id, root, vowel, consonant in zip(image_ids, roots, vowels, consonants):\n",
    "        for root, vowel, consonant in zip(roots, vowels, consonants):\n",
    "            #원본\n",
    "            #row_id.append(image_id + '_consonant_diacritic')\n",
    "            #target.append(consonant)\n",
    "            #row_id.append(image_id + '_grapheme_root')\n",
    "            #target.append(root)\n",
    "            #row_id.append(image_id + '_vowel_diacritic')\n",
    "            #target.append(vowel)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #roots_prob_ghost.append(roots)\n",
    "            #vowels_prob_ghost.append(vowels)\n",
    "            #consonants_prob_ghost.append(consonants)             \n",
    "            \n",
    "            \n",
    "            roots_prob_dense.append(root)\n",
    "            vowels_prob_dense.append(vowel)\n",
    "            consonants_prob_dense.append(consonant)    \n",
    "            \n",
    "    del data\n",
    "    del dataset\n",
    "    del data_loader\n",
    "    collected = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_all=[]\n",
    "vowels_all=[]\n",
    "consonants=[]\n",
    "\n",
    "#코드 수정해서 roots_prob_ghost_q 대신 roots_prob_ghost 사용\n",
    "\n",
    "for i in range(len(roots_prob_ghost)):\n",
    "    xxxx=(roots_prob_ghost[i] +roots_prob_effi[i] + roots_prob_res[i]*2+roots_prob_dense[i])/5\n",
    "    #xxxx=(roots_prob_ghost[i] +roots_prob_effi[i] + roots_prob_res[i])/3\n",
    "    #xxxx=(roots_prob_ghost[i] + roots_prob_res[i])/2\n",
    "    root_all.append(xxxx)\n",
    "    \n",
    "for i in range(len(roots_prob_ghost)):\n",
    "    xxxx=(vowels_prob_ghost[i] +vowels_prob_effi[i] + vowels_prob_res[i]*2+vowels_prob_dense[i])/5\n",
    "    #xxxx=(vowels_prob_ghost[i] +vowels_prob_effi[i] + vowels_prob_res[i])/3\n",
    "    #xxxx=(vowels_prob_ghost[i] + vowels_prob_res[i])/2\n",
    "    vowels_all.append(xxxx)\n",
    "    \n",
    "for i in range(len(roots_prob_ghost)):\n",
    "    xxxx=(consonants_prob_ghost[i] +consonants_prob_effi[i] + consonants_prob_res[i]*2+consonants_prob_dense[i])/5\n",
    "    #xxxx=(consonants_prob_ghost[i] +consonants_prob_effi[i] + consonants_prob_res[i])/3\n",
    "    #xxxx=(consonants_prob_ghost[i] + consonants_prob_res[i])/2\n",
    "    consonants.append(xxxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(root_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vowels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(consonants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(root_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=[]\n",
    "\n",
    "for i in range(len(root_all)):\n",
    "    targets.append(np.argmax(root_all[i]))\n",
    "    targets.append(np.argmax(vowels_all[i]))\n",
    "    targets.append(np.argmax(consonants[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.56s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create Submission File\n",
    "tgt_cols = ['grapheme_root','vowel_diacritic','consonant_diacritic']\n",
    "\n",
    "id_get=[]\n",
    "\n",
    "# Loop through Test Parquet files (X)\n",
    "for i in tqdm(range(0, 4)):\n",
    "    # Test Files Placeholder\n",
    "    test_files = []\n",
    "\n",
    "    # Read Parquet file\n",
    "    df = pd.read_parquet(os.path.join(DIR, test_loc+str(i)+'.parquet'))\n",
    "    # Get Image Id values\n",
    "    [id_get.append(nn) for nn in df['image_id'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list=[]\n",
    "for i in id_get:\n",
    "    id_list.append(i +\"_\"+tgt_cols[0])\n",
    "    id_list.append(i +\"_\"+ tgt_cols[1])\n",
    "    id_list.append(i +\"_\"+ tgt_cols[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.DataFrame(targets,id_list).reset_index()\n",
    "submission.columns=[\"row_id\",\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_0_grapheme_root</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_0_vowel_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_0_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_1_grapheme_root</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_1_vowel_diacritic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Test_1_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Test_2_grapheme_root</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Test_2_vowel_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Test_2_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Test_3_grapheme_root</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Test_3_vowel_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Test_3_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Test_4_grapheme_root</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Test_4_vowel_diacritic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Test_4_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Test_5_grapheme_root</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Test_5_vowel_diacritic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Test_5_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Test_6_grapheme_root</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Test_6_vowel_diacritic</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Test_6_consonant_diacritic</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Test_7_grapheme_root</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Test_7_vowel_diacritic</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Test_7_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Test_8_grapheme_root</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Test_8_vowel_diacritic</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Test_8_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Test_9_grapheme_root</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Test_9_vowel_diacritic</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Test_9_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Test_10_grapheme_root</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Test_10_vowel_diacritic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Test_10_consonant_diacritic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Test_11_grapheme_root</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Test_11_vowel_diacritic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Test_11_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         row_id  target\n",
       "0          Test_0_grapheme_root       3\n",
       "1        Test_0_vowel_diacritic       0\n",
       "2    Test_0_consonant_diacritic       0\n",
       "3          Test_1_grapheme_root      93\n",
       "4        Test_1_vowel_diacritic       2\n",
       "5    Test_1_consonant_diacritic       0\n",
       "6          Test_2_grapheme_root      19\n",
       "7        Test_2_vowel_diacritic       0\n",
       "8    Test_2_consonant_diacritic       0\n",
       "9          Test_3_grapheme_root     115\n",
       "10       Test_3_vowel_diacritic       0\n",
       "11   Test_3_consonant_diacritic       0\n",
       "12         Test_4_grapheme_root      55\n",
       "13       Test_4_vowel_diacritic       4\n",
       "14   Test_4_consonant_diacritic       0\n",
       "15         Test_5_grapheme_root     115\n",
       "16       Test_5_vowel_diacritic       2\n",
       "17   Test_5_consonant_diacritic       0\n",
       "18         Test_6_grapheme_root     147\n",
       "19       Test_6_vowel_diacritic       9\n",
       "20   Test_6_consonant_diacritic       5\n",
       "21         Test_7_grapheme_root     137\n",
       "22       Test_7_vowel_diacritic       7\n",
       "23   Test_7_consonant_diacritic       0\n",
       "24         Test_8_grapheme_root     119\n",
       "25       Test_8_vowel_diacritic       9\n",
       "26   Test_8_consonant_diacritic       0\n",
       "27         Test_9_grapheme_root     133\n",
       "28       Test_9_vowel_diacritic      10\n",
       "29   Test_9_consonant_diacritic       0\n",
       "30        Test_10_grapheme_root     148\n",
       "31      Test_10_vowel_diacritic       1\n",
       "32  Test_10_consonant_diacritic       4\n",
       "33        Test_11_grapheme_root      21\n",
       "34      Test_11_vowel_diacritic       2\n",
       "35  Test_11_consonant_diacritic       0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
